{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\ket}[1]{\\left|#1\\right>}$\n",
    "\n",
    "$\\newcommand{\\bra}[1]{\\left<#1\\right|}$\n",
    "\n",
    "$\\newcommand{\\braket}[2]{\\left<#1 | #2\\right>}$\n",
    "\n",
    "$\\newcommand{\\expectation}[1]{\\left<#1\\right>}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Max Cut Problem\n",
    "\n",
    "#### References\n",
    "Qiskit Max Cut tutorial: https://qiskit.org/textbook/ch-applications/qaoa.html <br>\n",
    "Qiskit VQE tutorial: https://qiskit.org/textbook/ch-applications/vqe-molecules.html <br>\n",
    "Wikipedia: https://en.wikipedia.org/wiki/Maximum_cut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To import all the functions defined in the notebook\n",
    "from  Functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Definition\n",
    "\n",
    "Let's consider a non-directed graph with $n$ vertices and $m$ edges.\n",
    "\n",
    "The Max Cut problems aim to find the two complementary subsets of vertices such that the number of edges connecting vertices of different subsets is maximal.\n",
    "\n",
    "This can be more easily visualized through an example, so that we can consider a graph G(V,E) with:\n",
    "- n = 5 vertices: $V = \\{V_1, V_2, V_3, V_4, V_5\\}$;\n",
    "- m = 6 edges: $E = \\{(0,1),(0,2),(1,2),(3,2),(3,4),(4,2)\\}$;\n",
    "- as we can see below, the graph is organized so that it recalls the shape of a butterfly.\n",
    "\n",
    "We can use a small piece of code to formalize the graph and show it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools to handle general graphs\n",
    "import networkx as nx\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Graph parameters \n",
    "n = 5\n",
    "V = np.arange(0,n,1)\n",
    "#   (v1,v2, weight)\n",
    "E = [(0, 1, 1.0),\n",
    "     (0, 2, 1.0),\n",
    "     (1, 2, 1.0),\n",
    "     (3, 2, 1.0),\n",
    "     (3, 4, 1.0),\n",
    "     (4, 2, 1.0)] \n",
    "\n",
    "# Generating the butterfly graph with 5 nodes\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(V)\n",
    "G.add_weighted_edges_from(E)\n",
    "\n",
    "# Plot the graph\n",
    "colors       = ['r' for node in G.nodes()]\n",
    "default_axes = plt.axes(frameon=True)\n",
    "pos          = nx.spring_layout(G)\n",
    "\n",
    "nx.draw_networkx(G, \n",
    "                 node_color = colors, \n",
    "                 node_size  = 600, \n",
    "                 alpha      = 1, \n",
    "                 ax         = default_axes, \n",
    "                 pos        = pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly a combinatorial optimization problem, since in principle we should try all the possible compositions of subsets and count the number of edges connecting vertices of different subsets.\n",
    "\n",
    "We can formalize our problem as a quadratic unconstrained binary optimization problem (QUBO), if we define the two subsets as $V1$ and $V2$ so that:\n",
    "- the vertices in $V1$ get are assigned a value 0: $x_i = 0 ~\\forall~ V_i \\in V1$;\n",
    "- the vertices in $V2$ get are assigned a value 0: $x_i = 1 ~\\forall~ V_i \\in V2$.\n",
    "\n",
    "Additionally, we introduce a weight matrix $w_{ij}$ with:\n",
    "- $w_{ii} = 0$ (a vertex is never connected to itself);\n",
    "- $w_{ij} = 1$ for existing edges;\n",
    "- $w_{ij} = 0$ for if vertex $V_i$ and vertex $V_j$ are not connected by any edge;\n",
    "- $w_{ij} = w_{ji}$.\n",
    "\n",
    "Thanks to this, we can defined a cost function that we would like to maximize:\n",
    "\n",
    "$$ C(\\textbf{x}) = \\sum_{i,j = 1}^n w_{ij} x_i (1 - x_j)$$\n",
    "\n",
    "where we can see that if two vertices belong to the same subset, the contribution to the cost function is 0 (at least one of the two terms $x_i$ or $(1 - x_j)$ is 0), while for vertices belonging to complementary subsets, the contribution is 1. The fact that $x_i$ must be 1 and $x_j$ must be 0, avoids counting twice the same edge.\n",
    "\n",
    "A more general approach may introduce different weights for different edges, so that $w_{ij} \\neq 1$, but always keeping $w_{ij} > 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Resolution: Brute Force Approach\n",
    "\n",
    "Independently on the values of the weights, the problem is $NP$, since testing all the possible combinations of subsets $V1$ and $V2$ requires $2^n - 2$ (all the element in $V1$ or all the element in $V2$ are not valid solutions) evaluations of the cost function.\n",
    "This approach is called *brute force* and is strongly inefficient, so that it cannot be used even for not-so-large values of n.\n",
    "\n",
    "We can try and implement such approach in this case and use the results as a cross-check to test alternative ways of solving the problem.\n",
    "\n",
    "In particular, in order to have just one possible solution, we are going to give all the edges weight 1, but the edges connecting to vertes $V_2$, which will have weight 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "# number of characters\n",
    "n = 5\n",
    "\n",
    "# W matrix definition\n",
    "W = np.array([[0, 1, 2, 0, 0],\n",
    "              [1, 0, 2, 0, 0],\n",
    "              [2, 2, 0, 2, 2],\n",
    "              [0, 0, 2, 0, 1],\n",
    "              [0, 0, 2, 1, 0]])\n",
    "\n",
    "best_cost_brute = 0\n",
    "\n",
    "# computing all possible combinations\n",
    "for b in range(2**n):\n",
    "    # x stores all the 2^n possible combinations of 0 and 1\n",
    "    # for a vector of length n \n",
    "    x = [int(t) for t in reversed(list(bin(b)[2:].zfill(n)))]\n",
    "\n",
    "    # initialize cost function value\n",
    "    cost = 0\n",
    "    # scan all possible costs and keep the highest one\n",
    "    # (now we want to maximize our score!)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            cost = cost + W[i,j]*x[i]*(1 - x[j])\n",
    "    if best_cost_brute < cost:\n",
    "        best_cost_brute = cost\n",
    "        xbest_brute = x \n",
    "    print('case = ' + str(x)+ ' score = ' + str(cost))\n",
    "\n",
    "# Showing results    \n",
    "colors = ['r' if xbest_brute[i] == 0 else 'b' for i in range(n)]\n",
    "nx.draw_networkx(G, node_color=colors)\n",
    "print('\\nBest solution = ' + str(xbest_brute) + ' cost = ' + str(best_cost_brute)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected by the way we constructed the problem, the highest score is obtained when $V_2$ is alone in one of the two subsets of $V$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Resolution: Ising Hamiltonian\n",
    "\n",
    "If we want to try and solve the problem more efficiently using a quantum computer, the first step consists in transforming it from a QUBO problem to a Ising Hamiltonian. To get the solution of the problem, we will have to find the fundamental state of the Hamiltonian.\n",
    "\n",
    "The result is the same (even if we are now going to look for a minimum, instead of a maximum), but this new formalism better adapts to the dual state that a qbit can assume:\n",
    "\n",
    "$\\ket{\\psi} = \\alpha \\ket{0} + \\beta \\ket{1}$\n",
    "\n",
    "where $\\alpha$ and $\\beta$ are complex coefficients that satisfy the relation:\n",
    "\n",
    "$ |\\alpha|^2 + |\\beta|^2 = 1 $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, we have to perform some transformations to the original formulation of the problem:\n",
    "- $x_i \\rightarrow \n",
    "    \\dfrac{1}{2}\n",
    "    (\\mathbb{1} + \\sigma_z)_i = \n",
    "    \\dfrac{1}{2}\n",
    "    \\left[\n",
    "    \\mathbb{1} + \n",
    "    \\begin{bmatrix}\n",
    "    1 &  0 \\\\\n",
    "    0 & -1\n",
    "    \\end{bmatrix}\n",
    "    \\right]_i = \n",
    "    \\begin{bmatrix}\n",
    "    1 & 0 \\\\\n",
    "    0 & 0\n",
    "    \\end{bmatrix}_i\n",
    "    $<br>\n",
    "    where the operator acts only on the corresponding states and has the following properties:\n",
    "    - $ \\begin{bmatrix}\n",
    "        1 & 0 \\\\\n",
    "        0 & 0\n",
    "        \\end{bmatrix}\n",
    "        \\begin{bmatrix}\n",
    "        1 \\\\\n",
    "        0\n",
    "        \\end{bmatrix} = \n",
    "        1 \\cdot\n",
    "        \\begin{bmatrix}\n",
    "        1 \\\\\n",
    "        0\n",
    "        \\end{bmatrix}$ <br>\n",
    "        $\\begin{bmatrix}\n",
    "        1 \\\\\n",
    "        0\n",
    "        \\end{bmatrix}$ is eigenvector of \n",
    "        $\\begin{bmatrix}\n",
    "        1 & 0 \\\\\n",
    "        0 & 0\n",
    "        \\end{bmatrix}$\n",
    "        with eigenvalue 1. <br>\n",
    "        This means that $x_i = 1 \\rightarrow         \n",
    "        \\begin{bmatrix}\n",
    "        1 \\\\\n",
    "        0\n",
    "        \\end{bmatrix} = \\ket{1}$\n",
    "    - $ \\begin{bmatrix}\n",
    "        1 & 0 \\\\\n",
    "        0 & 0\n",
    "        \\end{bmatrix}\n",
    "        \\begin{bmatrix}\n",
    "        0 \\\\\n",
    "        1\n",
    "        \\end{bmatrix} = \n",
    "        0 \\cdot\n",
    "        \\begin{bmatrix}\n",
    "        0 \\\\\n",
    "        1\n",
    "        \\end{bmatrix}$ <br>\n",
    "        $\\begin{bmatrix}\n",
    "        0 \\\\\n",
    "        1\n",
    "        \\end{bmatrix}$ is eigenvector of \n",
    "        $\\begin{bmatrix}\n",
    "        1 & 0 \\\\\n",
    "        0 & 0\n",
    "        \\end{bmatrix}$\n",
    "        with eigenvalue 0. <br>\n",
    "        This means that $x_i = 0 \\rightarrow         \n",
    "        \\begin{bmatrix}\n",
    "        0 \\\\\n",
    "        1\n",
    "        \\end{bmatrix} = \\ket{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- consequently, we will replace:\n",
    "$(1 - x_i) \\rightarrow \n",
    "    \\left[\n",
    "    \\mathbb{1} -     \n",
    "    \\begin{bmatrix}\n",
    "    1 & 0 \\\\\n",
    "    0 & 0\n",
    "    \\end{bmatrix}\n",
    "    \\right]_i = \n",
    "    \\begin{bmatrix}\n",
    "    0 & 0 \\\\\n",
    "    0 & 1\n",
    "    \\end{bmatrix}_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for every entry of the original $n x n$ QUBO matrix, take the entry $(i,j)$ and multiply it by the tensor product from $1$ to $n$ of $2 x 2$ identities, with the excpetion of the $i$-th and $j$-th terms of the product, which are the $2 x 2$ matrices corresponding to $x_i$ and $(1 - x_j)$. The sum of all these products is a diagonal $2^n x 2^n$ matrix, whose entries are the expectation values obtained with the *brute force* algorithm and corresponds to the Ising Hamiltonian associated to the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the process of converting a QUBO problem is not straightforward, let's make it clearer by doing it for the current problem, using a simple function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 2x2 matrices we need\n",
    "\n",
    "# (1 + pauli_z)/2\n",
    "sigma_z = np.array([[1, 0], [0, 0]])\n",
    "\n",
    "# (1 - sigma_z)\n",
    "minus_z = np.array([[0, 0], [0, 1]])\n",
    "\n",
    "# Identity\n",
    "id_matrix = np.array([[1, 0], [0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual function\n",
    "def qubo_to_ising(input_Q):\n",
    "    n = len(input_Q)\n",
    "    print(\"input:\")\n",
    "    print(input_Q)\n",
    "    print(\"\")\n",
    "    \n",
    "    # initialize H\n",
    "    H = 0\n",
    "\n",
    "    # compute the contribution of the i,j term to the Hamiltonian\n",
    "    # i = left-side term = x_i (corresponds to sigma_z)\n",
    "    for i in range(n):\n",
    "        # j = right-side term = (1 - x_j) (corresponds to minus_z)\n",
    "        for j in range(n):            \n",
    "            # first term\n",
    "            matrix_ij = 0\n",
    "            if i == 0:\n",
    "                matrix_ij = sigma_z\n",
    "            elif j == 0:\n",
    "                matrix_ij = minus_z\n",
    "            else:\n",
    "                matrix_ij = id_matrix\n",
    "            \n",
    "            # tensor product n times\n",
    "            for k in range(1,n):\n",
    "                if i == k:\n",
    "                    new_term = sigma_z\n",
    "                elif j == k:\n",
    "                    new_term = minus_z\n",
    "                else:\n",
    "                    new_term = id_matrix                \n",
    "                matrix_ij = np.kron(matrix_ij, new_term)\n",
    "\n",
    "            # multiply by the i,j term of input_Q \n",
    "            matrix_ij = matrix_ij * input_Q[i,j]\n",
    "            \n",
    "            # sum\n",
    "            H = H + matrix_ij\n",
    "    \n",
    "    return(-H) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate our QUBO matrix to a Ising Hamiltonian\n",
    "H = qubo_to_ising(W)\n",
    "\n",
    "print('Ising Hamiltonian dimensions:' + str(H.shape))\n",
    "print(\"\")\n",
    "\n",
    "# Check eigenvalues\n",
    "print(\"Ising eigenvalues:\")\n",
    "eigenvalues = []\n",
    "for i in range(len(H)):\n",
    "    eigenvalues.append(H[i,i])\n",
    "print(eigenvalues)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Resolution: Variational Quantum Eigensolver (VQE)\n",
    "\n",
    "We have seen that the Ising formulation is equivalent to the standard QUBO formulation of optimization problem and we state that it is more suited the resolution on a quantum computer. On the other hand, we still need $2^n$ evaluations of the Hamiltonian if we want to find the optimal solution.\n",
    "\n",
    "One possible way to exploit quantum computers to try and solve optimization problems more efficiently is through the so-called Variational Quantum Eigensolver (VQE) algorithm.\n",
    "\n",
    "It exploits the rapidity of a quantum computer in evaluating the cost function for a given quantum state $\\ket{\\psi}$ and associates it with a classical optimizer that helps in finding the optimal one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VQE: basic concepts\n",
    "\n",
    "To uderstand the idea behind VQE, we start by introducing the concepts of eigenvalue and eigenvector (or eigenstate), defined through the following relation:\n",
    "\n",
    "$$ H \\ket{\\psi_i} = \\lambda_i \\ket{\\psi_i}$$\n",
    "\n",
    "where $H$ is the matrix describing the Hamiltonian, $\\lambda_i$ is a eigenvalue and $\\ket{\\psi_i}$ is a eigenvector.\n",
    "In our case, the Hamiltonian $H$ is described by a diagonal matrix and the eigenvalues correspond to its diagonal entries and the eigenstates are the vectors:\n",
    "\n",
    "$$ \\ket{\\psi_i} = \\{ \\ket{00000}, \\ket{00001}, \\ket{00010}, \\ket{00011}, ...\\} $$\n",
    "\n",
    "This follows from the fact that in quantum mechanics, the outcome of a measurement can give only a discrete set of results. In particular, this set of results corresponds to the eigenvalues of the Hamiltonian $H$ describing the quantum system that we are measuring and each eigenvalue is associated to one eigenvector, or eigenstate of the system. \n",
    "\n",
    "The eigenvectors represent a basis of the space of the possible states of the quantum system, so that a general state $\\psi$ can be written as:\n",
    "\n",
    "$$ \\ket{\\psi} = \\sum_i^N \\alpha_i \\ket{\\psi_i}$$\n",
    "\n",
    "where in our case $N = 2^n$ is the number of eigenvalues and $\\alpha_i$ is the projection of $\\ket{\\psi}$ on the eigenvector $\\ket{\\psi_i}$:\n",
    "\n",
    "$$ \\alpha_i = \\braket{\\psi_i}{\\psi} $$\n",
    "\n",
    "And the Hamiltonian can be expressed as:\n",
    "\n",
    "$$ H = \\sum_i^{N} \\lambda_i \\ket{\\psi_i} \\bra{\\psi_i}$$\n",
    "\n",
    "The solution of our problem is the eigenvector associated to the smallest eigenvalue (let's call them $\\lambda_{min}$ and $\\ket{\\psi_{min}}$). \n",
    "In general, the outcome of a measurement (or expectation value) is always larger than the one obtained when the system is in the *fundamental state* $\\ket{\\psi_{min}}$:\n",
    "\n",
    "$$ \\lambda_{min} = \\expectation{\\psi_{min}|H|\\psi_{min}} \\leq\n",
    "\\expectation{\\psi|H|\\psi} = \n",
    "\\bra{\\psi} \\left( \\sum_i^{N} \\lambda_i \\ket{\\psi_i} \\bra{\\psi_i} \\right) \\ket{\\psi} = \n",
    "\\sum_i^{N} \\lambda_i \\braket{\\psi}{\\psi_i} \\braket{\\psi_i}{\\psi} = \n",
    "\\sum_i^{N} \\lambda_i |\\braket{\\psi_i}{\\psi}|^2 $$\n",
    "\n",
    "In other words, a large projection of the current state on the fundamental state, which is our solution, will produce a small expected value.\n",
    "\n",
    "The idea of VQE is to start with a reasonable ansatz for $\\ket{\\psi}$ (which for example is a superposition of all the possible eigenstates) and iteratively changing its eigenstate composition, typically through a series of rotations (we call this *optimization*), until we find the optimal solution or until we are satisfied with how close we are to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the expected value\n",
    "\n",
    "It is important at this point make that a single measurement gives only one of the possible results allowed.\n",
    "\n",
    "For example, in our case, if we prepare our state $\\ket{\\psi}$ such that it corresponds to the case (0, 0, 1, 0, 0), we will get, for every measurement, the result $\\lambda_{min} = -8$.\n",
    "In general, keeping in mind the probabilistic nature of quantum mechanics, a state:\n",
    "\n",
    "$$ \\ket{\\psi} = \\sum_i^N \\alpha_i \\ket{\\psi_i} $$\n",
    "\n",
    "will return as result the eigenvalue $\\lambda_i$ with probability $| \\alpha_i|^2$.\n",
    "\n",
    "This means that, for every state $\\ket{\\psi}$ that we consider, several measurements have to be performed in order to have an idea of how *large* or *small* the expected value is.\n",
    "\n",
    "Moreover, in our simple case we know all the eigenvalues of the Hamiltonian, while in general they may be so many that it is not convenient to explicitly get them, since it would correspond to solve the problem by *brute force*, making the optimization algorithm role even more delicate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VQE: Ansatz\n",
    "\n",
    "First of all, when preparing the ansatz for our solution, we have to consider that we will need one qbit for every vertex of our graph. In our case, we will need $n = 5$ qbits.\n",
    "\n",
    "Then, we want our ansatz:\n",
    "- to be able to cover the largest possible number of states $\\rightarrow$ more parameters;\n",
    "- to have a small number of gates: many gates may introduce errors and may make more difficult to converge towards a sensible solution $\\rightarrow$ less parameters.\n",
    "\n",
    "The choice will have to be a trade-off between these two opposite requirements.\n",
    "\n",
    "Among many possible possibilities, the so-called RY ansatz is quite popular and consists of:\n",
    "1. put every qbit in the $\\ket{+} = \\dfrac{\\ket{0} + \\ket{1}}{\\sqrt{2}}$ state through a rotation of $\\frac{\\pi}{2}$ around the y-axis of its Bloch sphere;\n",
    "- connect (or introduce entanglement among) different qbits, for example between pair of qbits;\n",
    "- introduce for each qbit a rotation around the y-axis of its Bloch sphere (RY-gate). The rotation angles are the parameters to be adjusted during the optimization process;\n",
    "- repeat step 2. and 3. for a chosen number of times, keeping in mind that more RY-gates means more parameters for the optimizer.\n",
    "\n",
    "The entanglement between two qbits can be obtained by applying a controlled gate, a gate that applies a transformation on a target qbit only if the control qbit is in the $\\ket{1}$ state.\n",
    "In our case, we will apply controlled z-gates.\n",
    "\n",
    "The RY ansatz is particularly popular since it allows to span a large number of states without introducing any complex phase, thanks to the fact that all the rotations are performed around the y- axis of the Bloch sphere.\n",
    "\n",
    "Let's try and prepare the ansatz for our problem using qiskit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, execute, Aer\n",
    "\n",
    "PI = np.pi\n",
    "\n",
    "# Number of qbits\n",
    "n = 5\n",
    "\n",
    "# Define the Quantum and Classical Registers\n",
    "q = QuantumRegister(n)\n",
    "c = ClassicalRegister(n)\n",
    "\n",
    "# Build the circuit for the ansatz\n",
    "circuit = QuantumCircuit(q, c)\n",
    "\n",
    "# Put all the qbits in the |+> state\n",
    "theta_hadamard = [PI/2,PI/2,PI/2,PI/2,PI/2]\n",
    "for i in range(n):\n",
    "    circuit.ry(theta_hadamard[i],q[i])\n",
    "circuit.barrier()\n",
    "\n",
    "# Apply controlled-z gates (first layer)\n",
    "for i in range(n-1):\n",
    "    circuit.cz(q[i], q[i+1])\n",
    "\n",
    "# Introduce RY-gates (first layer)\n",
    "theta_0 = [0.,0.,0.,0.,0.]\n",
    "for j in range(n):\n",
    "    circuit.ry(theta_0[j],q[j])\n",
    "circuit.barrier()\n",
    "\n",
    "# Apply controlled-z gates (second layer)\n",
    "for i in range(n-1):\n",
    "    circuit.cz(q[i], q[i+1])\n",
    "    \n",
    "# Introduce RY-gates (second layer)\n",
    "theta_1 = [0.,0.,0.,0.,0.]\n",
    "for j in range(n):\n",
    "    circuit.ry(theta_1[j],q[j])\n",
    "circuit.barrier()\n",
    "\n",
    "# Close the circuit with qbits measurements\n",
    "circuit.measure(q, c)\n",
    "\n",
    "# Draw the circuit    \n",
    "circuit.draw(output='mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the circuit on a simulator\n",
    "job = execute(circuit, \n",
    "              backend = Aer.get_backend('qasm_simulator'), \n",
    "              shots   = 1024)\n",
    "\n",
    "result = job.result()\n",
    "\n",
    "# Print the result\n",
    "print(result.get_counts(circuit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the result\n",
    "from qiskit.visualization import plot_histogram\n",
    "\n",
    "plot_histogram(result.get_counts(circuit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function evaluation\n",
    "\n",
    "So we have been able to prepare a circuit for the ansatz of our optimal solution and we have evaluated it 1024 times, observing that all the possible outcomes are represented almost uniformly.\n",
    "\n",
    "However, if we want to optimize the 15 rotation angles we introduced to obtain the optimal solution, this is not enough: to decide if our current solution is good enough or we need more iterations to tune its paramters, we need to evaluate its cost function.\n",
    "\n",
    "Since we are evaluating many times (1024 in our case) the cost function, we will have many values to deal with and we can choose among different figures of merit to extract a quantitative evaluation of the goodness of the current solution.\n",
    "The more intuitive and naive is the mean value, which we implement here.\n",
    "\n",
    "Using this figure of merit, our best solution will be the one giving the smallest cost function value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the value of the cost function\n",
    "\n",
    "# results: the results dictionary in the outcome of the circuit measurement\n",
    "# weights: the original QUBO matrix\n",
    "def cost_function_C(results, weights):\n",
    "    \n",
    "    # the eigenstates obtained by the evaluation of the circuit\n",
    "    eigenstates = list(results.keys())\n",
    "    \n",
    "    # how many times each eigenstate has been sampled\n",
    "    abundancies = list(results.values())\n",
    "    \n",
    "    # number of shots \n",
    "    shots = sum(results.values())\n",
    "    \n",
    "    # initialize the cost function\n",
    "    cost = 0\n",
    "    \n",
    "    for k in range(len(eigenstates)):\n",
    "        # ndarray of the digits extracted from the eigenstate string \n",
    "        x = np.array([int(num) for num in eigenstates[k]])\n",
    "        # Cost function due to the k-th eigenstate\n",
    "        cost = cost + x.dot(weights.dot(1-x)) * abundancies[k]\n",
    "    \n",
    "    return -cost / shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cost function given by the ansatz \n",
    "ansatz_cost = cost_function_C(result.get_counts(), W)\n",
    "print(ansatz_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "Now that we have an ansatz and we have defined our cost function, we want to use a classical optimizer to find the rotation angles that we need to obtain the solution of our problem.\n",
    "\n",
    "To do so, we have to define the ansatz as a parametric circuit, where the rotation angles of the RY gates are not given as numbers, but appear only as parameters that can be passed to the function that generates the circuit. \n",
    "\n",
    "This is not the only technical detail we have to consider, since in order to use the classical optimizer as it is defined in scipy libraries (https://docs.scipy.org/doc/scipy/reference/optimize.minimize-cobyla.html), it is a good idea to include the creation and execution of the circuit inside the function that evaluates its cost.\n",
    "\n",
    "Once also this change to the cost function definition is implemented, we can finally call the optimizer to get the angles that rotates our ansatz into the solution of the problem.\n",
    "\n",
    "For this problem, we are using the Constrained optimization by linear approximation (COBYLA), a derivative-free, numerical optimization method used for constrained problem (https://en.wikipedia.org/wiki/COBYLA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the circuit as a parametric function\n",
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, execute, Aer\n",
    "\n",
    "def VQE_circuit(theta, n, depth): \n",
    "    \"\"\"Creates a variational-form RY ansatz.\n",
    "    \n",
    "    theta: (depth+1 x n) matrix of rotation angles,\n",
    "    n: number of qbits,\n",
    "    depth: number of layers.\n",
    "    \"\"\"\n",
    "        \n",
    "    if len(theta.ravel()) != ((depth+1) * n):        \n",
    "        raise ValueError(\"Theta cannot be reshaped as a (depth+1 x n) matrix\")\n",
    "\n",
    "    theta.shape = (depth + 1, n)\n",
    "\n",
    "    # Define the Quantum and Classical Registers\n",
    "    q = QuantumRegister(n)\n",
    "    c = ClassicalRegister(n)\n",
    "\n",
    "    # Build the circuit for the ansatz\n",
    "    circuit = QuantumCircuit(q, c)\n",
    "\n",
    "    # Put all the qbits in the |+> state\n",
    "    for i in range(n):\n",
    "        circuit.ry(theta[0,i],q[i])\n",
    "    circuit.barrier()\n",
    "    \n",
    "    # Now introduce the z-gates and RY-gates 'depth' times\n",
    "    for j in range(depth):\n",
    "        # Apply controlled-z gates\n",
    "        for i in range(n-1):\n",
    "            circuit.cz(q[i], q[i+1])\n",
    "\n",
    "        # Introduce RY-gates\n",
    "        for i in range(n):\n",
    "            circuit.ry(theta[j+1,i],q[i])\n",
    "        circuit.barrier()\n",
    "    \n",
    "    # Close the circuit with qbits measurements\n",
    "    circuit.measure(q, c)\n",
    "    \n",
    "    return circuit    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw an example circuit\n",
    "theta = np.array([[PI/2,PI/2,PI/2,PI/2,PI/2],\n",
    "                  [0.,0.,0.,0.,0.,],\n",
    "                  [0.,0.,0.,0.,0.,]])\n",
    "\n",
    "n_qbits = 5 \n",
    "depth   = 2\n",
    "\n",
    "test_fig = VQE_circuit(theta, 5, 2).draw(output = 'mpl')\n",
    "test_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the creation and execution of the circuit inside the function\n",
    "# that computes the value of its cost\n",
    "\n",
    "# In case you want to use a real quantum device as backend\n",
    "from qiskit import IBMQ\n",
    "\n",
    "def cost_function_cobyla(params, \n",
    "                         weights,   # = W, \n",
    "                         n_qbits,   # = 5, \n",
    "                         depth,     # = 2,\n",
    "                         shots,     # = 1024\n",
    "                         cost,\n",
    "                         algorithm    = \"VQE\", \n",
    "                         alpha        = 0.5,\n",
    "                         backend_name = 'qasm_simulator',\n",
    "                         verbosity    = False):\n",
    "    \"\"\"Creates a circuit, executes it and computes the cost function.\n",
    "    \n",
    "    params: ndarray with the values of the parameters to be optimized,\n",
    "    weights: the original QUBO matrix of the problem,\n",
    "    n_qbits: number of qbits of the circuit,\n",
    "    depth: number of layers of the ciruit,\n",
    "    shots: number of evaluations of the circuit state,\n",
    "    cost: the cost function to be used. It can be: \n",
    "     - 'cost': mean value of all measured eigenvalues\n",
    "     - 'cvar': conditional value at risk = mean of the\n",
    "               alpha*shots lowest eigenvalues,\n",
    "    alpha: 'cvar' alpha parameter\n",
    "    verbosity: activate/desactivate some control printouts.\n",
    "    \n",
    "    The function calls 'VQE_circuit' to create the circuit, then\n",
    "    evaluates it and compute the cost function.\n",
    "    \"\"\"\n",
    "    \n",
    "    if (verbosity == True):\n",
    "        print(\"Arguments:\")\n",
    "        print(\"params  = \\n\", params)\n",
    "        print(\"weights = \\n\", weights)\n",
    "        print(\"qbits   = \", n_qbits)\n",
    "        print(\"depth   = \", depth)\n",
    "        print(\"shots   = \", shots)\n",
    "        print(\"cost    = \", cost)\n",
    "        print(\"algorithm = \", algorithm)\n",
    "        print(\"alpha   = \", alpha)\n",
    "        print(\"backend = \", backend_name)\n",
    "    \n",
    "    if algorithm == \"VQE\":\n",
    "        circuit = VQE_circuit(params, n_qbits, depth)\n",
    "    elif algorithm == \"QAOA\":\n",
    "        circuit = QAOA_circuit(params, weights, depth)\n",
    "    \n",
    "    if backend_name == 'qasm_simulator':\n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "    else:\n",
    "        provider = IBMQ.load_account()\n",
    "        backend = provider.get_backend(backend_name)\n",
    "    \n",
    "    # Execute the circuit on a simulator\n",
    "    job = execute(circuit, \n",
    "                  backend = backend, \n",
    "                  shots   = shots)\n",
    "    results = job.result()\n",
    "    \n",
    "    if cost == 'cost':\n",
    "        output = cost_function_C(results.get_counts(), weights)\n",
    "    elif cost == 'cvar':\n",
    "        output = cv_a_r(results.get_counts(), weights, alpha)\n",
    "    else:\n",
    "        raise ValueError(\"Please select a valid cost function\")\n",
    "    \n",
    "    if (verbosity == True):\n",
    "        print(\"cost = \", output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scipy implementation of the COBYLA optimizer\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Initial rotation angles of the RY ansatz\n",
    "theta = np.array([[PI/2,PI/2,PI/2,PI/2,PI/2],\n",
    "                  [0.,0.,0.,0.,0.,],\n",
    "                  [0.,0.,0.,0.,0.,]])\n",
    "\n",
    "WEIGHTS = W\n",
    "N_QBITS = 5\n",
    "DEPTH   = 2\n",
    "SHOTS   = 1024\n",
    "BACKEND = 'qasm_simulator'\n",
    "COST    = 'cost'\n",
    "\n",
    "# Classical optimizer tuning\n",
    "res = minimize(fun     = cost_function_cobyla, \n",
    "               x0      = theta.ravel(),     # the 'params' argument of 'cost_function_cobyla'\n",
    "               method  = 'COBYLA',          # we want to use the COBYLA optimization algorithm\n",
    "               options = {'maxiter': 500},  # maximum number of iterations\n",
    "               tol     = 0.0001,            # tolerance or final accuracy in the optimization \n",
    "               args    = (WEIGHTS, \n",
    "                          N_QBITS, \n",
    "                          DEPTH, \n",
    "                          SHOTS,\n",
    "                          COST,\n",
    "                          BACKEND))         # the arguments of 'cost_function_cobyla', except 'params'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the output distribution using the final parameters\n",
    "optimal_circuit = VQE_circuit(res.x, \n",
    "                              N_QBITS, \n",
    "                              DEPTH)\n",
    "\n",
    "backend = Aer.get_backend(BACKEND)\n",
    "\n",
    "counts = execute(optimal_circuit, \n",
    "                 backend, \n",
    "                 shots = SHOTS).result().get_counts(optimal_circuit)\n",
    "\n",
    "print(\"Optimal rotation angles:\\n\", res.x)\n",
    "print()\n",
    "\n",
    "# To trust the optimizer is fine, but it is better to check ;) \n",
    "print(\"Cost function with the optimal angles (according to scipy):\", res.fun)\n",
    "print(\"Cost function with the optimal angles (actual evaluation):\",  cost_function_cobyla(res.x, \n",
    "                                                                                          WEIGHTS, \n",
    "                                                                                          N_QBITS, \n",
    "                                                                                          DEPTH, \n",
    "                                                                                          SHOTS,\n",
    "                                                                                          COST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the result\n",
    "from qiskit.visualization import plot_histogram\n",
    "\n",
    "plot_histogram(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study of the Number of Shots \n",
    "\n",
    "We have seen that the VQE algorithm is able to find the solution of a QUBO problem, at least with the simple max-cut example that we used as benchmark.\n",
    "\n",
    "But the real challenge for quantum computers is managing to provide reliable solutions to such problems faster than classical computers can do with traditional algorithms.\n",
    "\n",
    "As we mentioned, one feature of quantum computers is that, in order to have a consistent estimation of the cost function associated to a particular configuration of a circuit and its parameters (rotation angles, in our case), its state has to be evaluated several times. The act of evaluating the state of a circuit is usually defined *shot*.\n",
    "\n",
    "Here, two opposite forces are acting:\n",
    "- More shots mean a more detailed and accurate knowledge of the circuit eigenstate composition;\n",
    "- But more shots mean also more time to reach the optimal solution.\n",
    "\n",
    "We would like now to perform a systematic study on how the number of shots affects both the convergence to the optimal solution and the time needed to obtain it.\n",
    "\n",
    "For this, we introduce three quantities:\n",
    "- To measure the convergence to the optimal solution, we define the overlap of the solution returned by the optimization process with the solution we found using the *brute force* approach, which is Sol = {[00100],[11011]};\n",
    "- To measure how much it takes to get the solution, we use two quantities:\n",
    "    - The time taken by the algorithm to carry out the optimization process, in seconds;\n",
    "    - The number of evaluations of the cost function times the number of shots. We think this should be a more robust estimator of the computational efficiency, since it corresponds to the number of execution of the ansatz circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you want to use a real quantum device as backend\n",
    "from qiskit import IBMQ\n",
    "\n",
    "# Is time a good figure of merit?\n",
    "# https://stackoverflow.com/questions/27728483/understanding-the-output-of-scipy-optimize-basinhopping\n",
    "\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def time_vs_shots(shots,\n",
    "                  weights,\n",
    "                  n_qbits,\n",
    "                  depth,\n",
    "                  backend_name,\n",
    "                  final_eval_shots,\n",
    "                  cost,\n",
    "                  alpha = 0.5,\n",
    "                  verbosity = False):\n",
    "    \"\"\"Returns the time taken to solve a VQE problem\n",
    "    as a function of the shots.    \n",
    "    \n",
    "    Input parameters:\n",
    "    shots: number of evaluations of the circuit state,\n",
    "    weights: the original QUBO matrix of the problem,\n",
    "    n_qbits: number of qbits of the circuit,\n",
    "    depth: number of layers of the ciruit,\n",
    "    backend_name: the name of the device where the optimization will be performed,\n",
    "    final_eval_shots: number of shots for the evaluation of the optimized circuit,\n",
    "    cost_f: the cost function to be used. It can be: \n",
    "     - 'cost': mean value of all measured eigenvalues\n",
    "     - 'cvar': conditional value at risk = mean of the\n",
    "               alpha*shots lowest eigenvalues,\n",
    "    alpha: 'cvar' alpha parameter\n",
    "    verbosity: activate/desactivate some control printouts.\n",
    "    \n",
    "    Output:\n",
    "    elapsed_time: time taken for the optimization (in seconds)\n",
    "    counts: the results of the optimization\n",
    "    shots: the 'shots' input parameter (it may be useful for analysis)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the rotation angles for the ansatz\n",
    "    theta_0       = np.repeat(PI/2, n_qbits)\n",
    "    theta_0.shape = (1, n_qbits)\n",
    "    theta_1       = np.zeros((depth, n_qbits))\n",
    "    theta         = np.concatenate((theta_0, theta_1), axis = 0) \n",
    "    \n",
    "    # Time starts with the optimization\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Classical optimizer tuning\n",
    "    res = minimize(fun     = cost_function_cobyla, \n",
    "                   x0      = theta.ravel(),     # the 'params' argument of 'cost_function_cobyla'\n",
    "                   method  = 'COBYLA',          # we want to use the COBYLA optimization algorithm\n",
    "                   options = {'maxiter': 500},  # maximum number of iterations\n",
    "                   tol     = 0.0001,            # tolerance or final accuracy in the optimization \n",
    "                   args    = (weights, \n",
    "                              n_qbits, \n",
    "                              depth, \n",
    "                              shots,\n",
    "                              cost,\n",
    "                              alpha,\n",
    "                              backend_name))    # the arguments of 'cost_function_cobyla', except 'params'\n",
    "\n",
    "    # Time stops when the optimization stops\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Total time taken for the optimization\n",
    "    elapsed_time = end_time - start_time \n",
    "\n",
    "    # Number of cost function evaluations during the optimization\n",
    "    n_func_evaluations = res.nfev\n",
    "\n",
    "    # Obtain the output distribution using the final parameters\n",
    "    optimal_circuit = VQE_circuit(res.x, \n",
    "                                  n_qbits, \n",
    "                                  depth)\n",
    "\n",
    "    # Define the backend for the evaluation of the optimal circuit\n",
    "    # - in case it is a simulator\n",
    "    if backend_name == 'qasm_simulator':\n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "    # - in case it is a real quantum device\n",
    "    else:\n",
    "        provider = IBMQ.load_account()\n",
    "        backend = provider.get_backend(backend_name)\n",
    "\n",
    "    # Get the results from the circuit with the optimized parameters    \n",
    "    counts = execute(optimal_circuit, \n",
    "                     backend, \n",
    "                     shots = final_eval_shots).result().get_counts(optimal_circuit)\n",
    "    \n",
    "    return elapsed_time, counts, shots, n_func_evaluations, final_eval_shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test once\n",
    "\n",
    "# Variables declaration\n",
    "WEIGHTS    = W\n",
    "N_QBITS    = 5\n",
    "DEPTH      = 2\n",
    "SHOTS      = 512\n",
    "BACKEND    = 'qasm_simulator'\n",
    "FINAL_EVAL = 8192\n",
    "COST       = 'cost' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute\n",
    "test_once = time_vs_shots(SHOTS,\n",
    "                  WEIGHTS,\n",
    "                  N_QBITS,\n",
    "                  DEPTH,\n",
    "                  BACKEND,\n",
    "                  FINAL_EVAL,\n",
    "                  COST) \n",
    "\n",
    "# Output object structure:\n",
    "# a[0]: elapsed time\n",
    "# a[1]: dictionary with {'eigenstate': frequency}\n",
    "# a[2]: number of shots\n",
    "# a[3]: number of cost function evaluation\n",
    "# a[4]: shots used in the evaluation of the optimal circuit\n",
    "test_once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A small scan, just for testing\n",
    "\n",
    "scan_results = []\n",
    "\n",
    "shots_list = [128, 256, 512, 1024, 2048, 3072, 4096]\n",
    "\n",
    "for shot in shots_list:\n",
    "    output = time_vs_shots(shot,\n",
    "                           WEIGHTS,\n",
    "                           N_QBITS,\n",
    "                           DEPTH,\n",
    "                           BACKEND,\n",
    "                           FINAL_EVAL,\n",
    "                           COST) \n",
    "\n",
    "    scan_results.append(output)\n",
    "        \n",
    "# Normalize results for plotting\n",
    "for res in scan_results:\n",
    "    for key, value in res[1].items():\n",
    "        res[1][key] = res[1][key] / res[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "for i in range(len(scan_results)):\n",
    "\n",
    "    # Compute overlap with correct solution\n",
    "    # Correct solution = {'11011', '00100'}\n",
    "    overlap = 0\n",
    "    for key, value in scan_results[i][1].items():\n",
    "        if key == '11011' or key == '00100':\n",
    "            overlap += value\n",
    " \n",
    "    # Start plotting\n",
    "    fig, ax = plt.subplots()\n",
    "    barplot = ax.bar(list(scan_results[i][1].keys()), \n",
    "                     scan_results[i][1].values(), \n",
    "                     color = 'lightblue')\n",
    "\n",
    "    # Cosmetics\n",
    "    ax.set_ylim(0.0, 1.2)\n",
    "    ax.set_ylabel('Probabilities')\n",
    "    ax.set_xticklabels(list(scan_results[i][1].keys()), rotation='65')\n",
    "\n",
    "    # Plot information\n",
    "    time_str    = str(np.around(scan_results[i][0],2))\n",
    "    shots       = str(scan_results[i][2]) \n",
    "    overlap_str = str(np.around(overlap,2))\n",
    "    n_eval      = str(scan_results[i][3])# * results[i][2])\n",
    "    \n",
    "    # Title\n",
    "    title = \"Shots: \" + shots\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # Result details printed on the plot\n",
    "    textstr = \"Time elapsed: \" + time_str + \"s - Overlap: \" + overlap_str + \" - N eval: \" + n_eval   \n",
    "    ax.text(0.05, 0.94, textstr, \n",
    "            transform = ax.transAxes, \n",
    "            fontsize  = 12,\n",
    "            verticalalignment='top')    \n",
    "    \n",
    "    # Horizontal lines grid\n",
    "    ax.yaxis.grid()\n",
    "    \n",
    "    # Do not cut labels when save as png or pdf\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save as png and pdf\n",
    "    filename = \"Shots_\" + shots\n",
    "    plt.savefig(filename + '.png')\n",
    "    plt.savefig(filename + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try and interpret the results obtained, we can plot some distributions we think can be of interest:\n",
    "1. Number of cost function evaluation versus shots;\n",
    "- Time taken to get the solution versus shots;\n",
    "- Time taken to get the solution versus number of cost function evaluations;\n",
    "- Time taken to get the solution versus (number of cost function evaluations times shots).\n",
    "- Time taken to get the solution versus log$_2$(shots);\n",
    "\n",
    "As we can see in the following plots:\n",
    "1. The number of cost function evaluations is quite flat versus the number of shots. Considering that the cost function, as we defined it, includes the execution of the circuit for *numberof shots* times, we can conclude that the number of shots does not significantly affect the capability of the optimization algorithm to find a valid solution.\n",
    "- Taking the previous observation into account, we would expect that increasing the number of shots would require more time to get the solution, since each evaluation of the cost function requires running the ansatz circuit *number of shots* times. However, this is not the case, at least if we look at the second plot, where the time taken to get to the solution is mainly flat versus the number of shots. We can interpret this thinking that the circuit evaluation takes a negligible time with respect to other operations performed by the classical optimizer. On the other hand, we have to take into account that the current results are obtained using a quantum device simulator that runs directly in the laptop used to execute the code. A more proper measure would involve running the whole process using a real quantum device. In that case, however it would be important to take into account in the time estimation, the time spent in the queue (if any) and other possible effects that may inflate our measurements. \n",
    "- We observe a direct dependency between time taken to get to the solution and number of evaluations of the cost function. This suggests, again, that the number of evaluations of the cost function is a valid estimator of the rapidity of the algorithm. Also in this case, a proper measurement using a real quantum device seems to be needed to confirm this impression.\n",
    "- Being the number of cost function evaluations flat versus the number of shots, plotting the elapsed time versus the product of the two quantities is basically the same as plotting the time taken versus the number of shots alone.\n",
    "- Plotting the elapsed time versus log$_2$(shots) seems to indicate a logaritmic dependence of the time versus the number of shots. This may be checked by running many times the optimization for each number of shots and considering the average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot function definition\n",
    "def scatter_plot(x, y, \n",
    "                 title = \"\", xlabel = \"\", ylabel = \"\", save_as = \"\", \n",
    "                 ylim = (-9999, -9999)):\n",
    "    # Plot declaration\n",
    "    fig, ax = plt.subplots()\n",
    "    local_plot = ax.scatter(x = x,\n",
    "                            y = y)\n",
    "\n",
    "    # Title\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # Cosmetics\n",
    "    if ylim == (-9999, -9999):\n",
    "        ax.set_ylim(0.0, 1.5*np.max(y))\n",
    "    else:    \n",
    "        ax.set_ylim(ylim)\n",
    "    ax.set_xlim(0.0, 1.1*np.max(x))\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    \n",
    "    # Save as png and pdf\n",
    "    if save_as != \"\":\n",
    "        plt.savefig(save_as + '.png')\n",
    "        plt.savefig(save_as + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the results so that it is easier to plot them\n",
    "\n",
    "# Create list of times\n",
    "ntimes = np.array([])\n",
    "for i in range(len(scan_results)):\n",
    "    ntimes = np.append(ntimes, scan_results[i][0])\n",
    "print(ntimes)\n",
    "\n",
    "# Create list of nfev\n",
    "nfevs = np.array([])\n",
    "for i in range(len(scan_results)):\n",
    "    nfevs = np.append(nfevs, scan_results[i][3])\n",
    "print(nfevs)\n",
    "\n",
    "# Create list of shots\n",
    "nshots = np.array([])\n",
    "for i in range(len(scan_results)):\n",
    "    nshots = np.append(nshots, scan_results[i][2])\n",
    "print(nshots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function evaluations vs shots\n",
    "scatter_plot(x       = nshots,\n",
    "             y       = nfevs,\n",
    "             title   = \"Number of cost function evaluations vs shots\",\n",
    "             xlabel  = \"Shots\",\n",
    "             ylabel  = \"Cost function evaluations\",\n",
    "             save_as = \"nfev_vs_shots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elapsed time vs shots\n",
    "scatter_plot(x       = nshots,\n",
    "             y       = ntimes,\n",
    "             title   = \"Elapsed time vs shots\",\n",
    "             xlabel  = \"Shots\",\n",
    "             ylabel  = \"Elapsed time [s]\",\n",
    "             save_as = \"time_vs_shots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elapsed time vs cost function evaluations\n",
    "scatter_plot(x       = nfevs,\n",
    "             y       = ntimes,\n",
    "             title   = \"Elapsed time vs number of cost function evaluations\",\n",
    "             xlabel  = \"Cost function evaluations\",\n",
    "             ylabel  = \"Elapsed time [s]\",\n",
    "             save_as = \"time_vs_nfev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elapsed time vs (cost function evaluations x shots)\n",
    "scatter_plot(x       = nshots*nfevs,\n",
    "             y       = ntimes,\n",
    "             title   = \"Elapsed time vs number of cost function evaluations x shots\",\n",
    "             xlabel  = \"(Cost function evaluations) x (shots)\",\n",
    "             ylabel  = \"Elapsed time [s]\",\n",
    "             save_as = \"time_vs_nfev_x_shots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elapsed time vs log2(shots)\n",
    "scatter_plot(x       = np.log2(nshots),\n",
    "             y       = ntimes,\n",
    "             title   = \"Elapsed time vs log2(shots)\",\n",
    "             xlabel  = \"log2(shots)\",\n",
    "             ylabel  = \"Elapsed time [s]\",\n",
    "             save_as = \"time_vs_log2shots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating the Optimization Several Times\n",
    "\n",
    "Even if the previous results give us a *qualitative* idea of how moving some parameters of the VQE algorithm can affect its rapidity and the goodness of the solution returned, if we want to have some really *quantitative* results, we need to systematically repeat the optimization several times for each value of *shots* that we decide to study.\n",
    "\n",
    "Additionally, it allows to introduce a different estimator of the goodness of the solution, maybe less intuitive with respect to the overlap, but more suited to the VQE algorithm: given a solution, we compute the cost function associated to each of the (hopefully few) eigenstates contributing to it and taking the one giving the smallest value as the *best candidate* to be considered as the optimal solution.\n",
    "If we repeat the optimization $N_{rep}$ times and we see that the *best candidate* is actually the optimal solution $N_{b-c}$ times, we can define the fraction of times (let's call it $F_{opt}$) in which we managed to extract from our solution the optimal solution of the problem:\n",
    "\n",
    "$$ F_{opt} = \\dfrac{N_{b-c}}{N_{rep}}$$\n",
    "\n",
    "This quantity gives us an idea of how many times we should repeat the optimization process if we want to be reasonably sure that at least one of our *best candidates* is also the optimal solution of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the value of the cost function of each eigenstate in a solution\n",
    "# and returns to 'best candidate' eigenstate\n",
    "\n",
    "# results_dict: the eigenstate-freq dictionary returned by 'time_vs_shots'\n",
    "# weights: the original QUBO matrix\n",
    "def best_candidate_finder(results_dict, \n",
    "                          weights):\n",
    "        \n",
    "    # the eigenstates obtained by the evaluation of the circuit\n",
    "    eigenstates = list(results_dict.keys())\n",
    "        \n",
    "    # initialize the cost function\n",
    "    min_cost = 0\n",
    "    best_candidate = 0\n",
    "    \n",
    "    for k in range(len(eigenstates)):\n",
    "        # ndarray of the digits extracted from the eigenstate string \n",
    "        x = np.array([int(num) for num in eigenstates[k]])\n",
    "        # Cost function of to the k-th eigenstate\n",
    "        cost = x.dot(weights.dot(1-x))\n",
    "        if cost > min_cost:\n",
    "            min_cost = cost\n",
    "            best_candidate = eigenstates[k]\n",
    "    \n",
    "    return best_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute F_opt\n",
    "def F_opt_finder(results_obj,\n",
    "                 n_shots,\n",
    "                 weights,\n",
    "                 opt_sol,\n",
    "                 n_eigenstates = 1000):\n",
    "    \"\"\"Returns the fraction of optimal solutions.\n",
    "    \n",
    "    Given the object returned by 'time_vs_shots',\n",
    "    computes the fraction of best_candidates solutions\n",
    "    which are optimal solutions.\n",
    "    \n",
    "    Inputs:\n",
    "    results_obj: the object returned by 'time_vs_shots',\n",
    "    n_shots: the 'number of shots' to investigate,\n",
    "    W: the original QUBO matrix,\n",
    "    opt_sol: list of the optimal solutions to the problem,\n",
    "    n_eigenstates: maximum number of eigenstates in a solution.\n",
    "    \"\"\"\n",
    "    # Initialize the counter of repetitions for the\n",
    "    # selected number of shots\n",
    "    N_rep = 0\n",
    "    # Initialize the counter of best candidates which \n",
    "    # are optimal solutions    \n",
    "    N_bc  = 0\n",
    "    # Scan all the entries of the object\n",
    "    for res in results_obj:\n",
    "        # Select only the entries corresponding to \n",
    "        # the selected number of shots\n",
    "        if res[2] == n_shots:\n",
    "            # If the number of shots is the one we want to check,\n",
    "            # sum 1 to the number of repetitions\n",
    "            N_rep += 1\n",
    "            # Find best candidate\n",
    "            bc = best_candidate_finder(res[1], weights)\n",
    "            # best candidate must contain the optimal solution\n",
    "            if bc in opt_sol:\n",
    "                # best candidate must have less than 'n_eigenstates' eigenstates\n",
    "                if len(res[1]) < n_eigenstates:\n",
    "                    N_bc += 1\n",
    "    # Initialize output value\n",
    "    F_opt = 0\n",
    "    # If N_rep is not 0, return the fraction of best candidates\n",
    "    # which are also optimal solutions\n",
    "    if N_rep != 0:\n",
    "        F_opt = N_bc / N_rep\n",
    "    else:\n",
    "        print(\"The number of shots selected is not present\")\n",
    "    return F_opt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can save the results to produce them once and analyze them later\n",
    "#https://stackoverflow.com/questions/4529815/saving-an-object-data-persistence\n",
    "    \n",
    "import pickle\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  \n",
    "        # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)   \n",
    "        print(\"Object saved as\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is useful to check the memory usage\n",
    "# https://stackoverflow.com/a/1094933/1870254\n",
    "\n",
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# A small scan, but we can get some results\n",
    "\n",
    "from sys import getsizeof\n",
    "\n",
    "N_repetitions = 100\n",
    "shots_list = [64, 128, 256, 512, 1024, 2048, 3072, 4096]\n",
    "\n",
    "for shot in shots_list:\n",
    "    results_current = []\n",
    "    output = 0\n",
    "    file_name = \"Scan_\" + str(shot) + \".pkl\"\n",
    "    for rep in range(N_repetitions): \n",
    "        output = time_vs_shots(shot,\n",
    "                               WEIGHTS,\n",
    "                               N_QBITS,\n",
    "                               DEPTH,\n",
    "                               BACKEND,\n",
    "                               FINAL_EVAL\n",
    "                               COST) \n",
    "        \n",
    "        if rep % 20 == 0:\n",
    "            print(\"Done with\", str(shot), \"shots, repetition\", rep)\n",
    "        results_current.append(output)\n",
    "                       \n",
    "    save_object(results_current, file_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "import pickle\n",
    "\n",
    "load_shots_list = [64, 128, 256, 512, 1024, 2048, 3072, 4096]\n",
    "\n",
    "scan = []\n",
    "\n",
    "for shot in load_shots_list:\n",
    "    load_file_name = \"Scan_\" + str(shot) + \".pkl\"\n",
    "    with open(load_file_name, 'rb') as input:\n",
    "        for pick in pickle.load(input): \n",
    "            scan.append(pick)\n",
    "\n",
    "# Normalize results for plotting\n",
    "for res in scan:\n",
    "    for key, value in res[1].items():\n",
    "        res[1][key] = res[1][key] / res[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of solutions containing the optimal solution:\")\n",
    "print()\n",
    "for shot in load_shots_list:\n",
    "    frac = F_opt_finder(scan, shot, W, ['00100', '11011'])\n",
    "    print(\"Case {0} shots: {1}%\".format(shot,frac*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the study suggest that for the simple problem we are considering, all the optimizations in which the circuit is measured at least 64 times per iteration, provide a solution containing the optimal solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Interpretation with Several Optimizations\n",
    "\n",
    "Now that we have produced 10 optimization for each choice of the number of shots, we can repeat the plots of the *Results Interpretation* section, in this case considering the average of the different quantities, to see if we observe some significant differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the results so that it is easier to plot them\n",
    "\n",
    "# Create list of times\n",
    "ntimes = np.array([])\n",
    "for i in range(len(scan)):\n",
    "    ntimes = np.append(ntimes, scan[i][0])\n",
    "#print(ntimes)\n",
    "\n",
    "# Create list of nfev\n",
    "nfevs = np.array([])\n",
    "for i in range(len(scan)):\n",
    "    nfevs = np.append(nfevs, scan[i][3])\n",
    "#print(nfevs)\n",
    "\n",
    "# Create list of shots\n",
    "nshots = np.array([])\n",
    "for i in range(len(scan)):\n",
    "    nshots = np.append(nshots, scan[i][2])\n",
    "#print(nshots)\n",
    "\n",
    "# Create list of number of eigenstates in the solution\n",
    "neigenst = np.array([])\n",
    "for i in range(len(scan)):\n",
    "    neigenst = np.append(neigenst, len(scan[i][1]))\n",
    "#print(neigenst)\n",
    "\n",
    "# Create list of cost function values\n",
    "ncost = np.array([])\n",
    "for i in range(len(scan)):\n",
    "    ncost = np.append(ncost, cost_function_C(scan[i][1], W))\n",
    "#print(ncost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the lists in a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(list(zip(ntimes, nfevs, nshots, neigenst, ncost)), \n",
    "               columns =['time', 'nfevs', 'shots', 'eigenstates', 'cost_func'])\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by shots and average\n",
    "df_plot = df.groupby(['shots']).mean()\n",
    "df_plot.reset_index(level=0, inplace=True)\n",
    "df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function evaluations vs shots\n",
    "scatter_plot(x       = df_plot.shots,\n",
    "             y       = df_plot.nfevs,\n",
    "             title   = \"Number of cost function evaluations vs shots\",\n",
    "             xlabel  = \"Shots\",\n",
    "             ylabel  = \"Cost function evaluations\",\n",
    "             save_as = \"nfev_vs_shots_avg10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elapsed time vs shots\n",
    "scatter_plot(x       = df_plot.shots,\n",
    "             y       = df_plot.time,\n",
    "             title   = \"Elapsed time vs shots\",\n",
    "             xlabel  = \"Shots\",\n",
    "             ylabel  = \"Elapsed time [s]\",\n",
    "             save_as = \"time_vs_shots_avg10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elapsed time vs cost function evaluations\n",
    "scatter_plot(x       = df_plot.nfevs,\n",
    "             y       = df_plot.time,\n",
    "             title   = \"Elapsed time vs number of cost function evaluations\",\n",
    "             xlabel  = \"Cost function evaluations\",\n",
    "             ylabel  = \"Elapsed time [s]\",\n",
    "             save_as = \"time_vs_nfev_avg10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elapsed time vs (cost function evaluations x shots)\n",
    "scatter_plot(x       = df_plot.shots*df_plot.nfevs,\n",
    "             y       = df_plot.time,\n",
    "             title   = \"Elapsed time vs number of cost function evaluations x shots\",\n",
    "             xlabel  = \"(Cost function evaluations) x (shots)\",\n",
    "             ylabel  = \"Elapsed time [s]\",\n",
    "             save_as = \"time_vs_nfev_x_shots_avg10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elapsed time vs log2(shots)\n",
    "scatter_plot(x       = np.log2(df_plot.shots),\n",
    "             y       = df_plot.time,\n",
    "             title   = \"Elapsed time vs log2(shots)\",\n",
    "             xlabel  = \"log2(shots)\",\n",
    "             ylabel  = \"Elapsed time [s]\",\n",
    "             save_as = \"time_vs_log2shots_avg10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function evaluations vs log2(shots)\n",
    "scatter_plot(x       = np.log2(df_plot.shots),\n",
    "             y       = df_plot.nfevs,\n",
    "             title   = \"Number of cost function evaluations vs shots\",\n",
    "             xlabel  = \"log2(Shots)\",\n",
    "             ylabel  = \"Cost function evaluations\",\n",
    "             save_as = \"nfev_vs_log2shots_avg10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many eigenstates in the solution?\n",
    "\n",
    "One additional quantity that we can measure is the number of eigenstates present in the solution. \n",
    "\n",
    "In fact, if we want to solve our problem through a *brute force* approach, we have to evaluate all the 32 possible eigenstates to get the corresponding eigenvalue (or cost function). While in this simple case this is not a problem at all, in general this is not a viable choice and this is the reason why VQE could be an interesting algorithm to solve combinatorial problems.\n",
    "\n",
    "But if the solution provided by VQE is itself nothing more than a superposition of all possible eigenstates, we are gaining nothing.\n",
    "\n",
    "For this reason, checking the number of eigenstates in the final solution can give significant hints on the quality of the solution returned by the optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of eigenstates in solution vs shots\n",
    "scatter_plot(x       = df_plot.shots,\n",
    "             y       = df_plot.eigenstates,\n",
    "             title   = \"Number of eigenstates in solution vs shots\",\n",
    "             xlabel  = \"Shots\",\n",
    "             ylabel  = \"Eigenstates\",\n",
    "             save_as = \"eigenst_vs_shots_avg10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering this, we can repeat the study on the fraction of valid solutions, but including now the number of eigenstates to decide whether we want to keep the solution or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Percentage of solutions containing the optimal solution,  \n",
    "without any limits on the number of eigenstates:\"\"\")\n",
    "print()\n",
    "fracs = []\n",
    "for shot in load_shots_list:\n",
    "    frac = F_opt_finder(scan, shot, W, ['00100', '11011'], 100)\n",
    "    print(\"Case {0} shots: {1}%\".format(shot,frac*100))\n",
    "    fracs.append(frac)\n",
    "    \n",
    "scatter_plot(x       = load_shots_list,\n",
    "             y       = fracs,\n",
    "             title   = \"Fraction of valid solutions\",\n",
    "             xlabel  = \"Shots\",\n",
    "             ylabel  = \"F_opt\",\n",
    "             save_as = \"valid_sol_32\",\n",
    "             ylim    = (0, 1.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Percentage of solutions containing the optimal solution and \n",
    "having less than 16 eigenstates:\"\"\")\n",
    "print()\n",
    "fracs = []\n",
    "for shot in load_shots_list:\n",
    "    frac = F_opt_finder(scan, shot, W, ['00100', '11011'], 16)\n",
    "    print(\"Case {0} shots: {1}%\".format(shot,frac*100))\n",
    "    fracs.append(frac)\n",
    "    \n",
    "scatter_plot(x       = load_shots_list,\n",
    "             y       = fracs,\n",
    "             title   = \"Fraction of valid solutions\",\n",
    "             xlabel  = \"Shots\",\n",
    "             ylabel  = \"F_opt\",\n",
    "             save_as = \"valid_sol_16\",\n",
    "             ylim    = (0, 1.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Percentage of solutions containing the optimal solution and \n",
    "having less than 12 eigenstates:\"\"\")\n",
    "print()\n",
    "fracs = []\n",
    "for shot in load_shots_list:\n",
    "    frac = F_opt_finder(scan, shot, W, ['00100', '11011'], 12)\n",
    "    print(\"Case {0} shots: {1}%\".format(shot,frac*100))\n",
    "    fracs.append(frac)\n",
    "    \n",
    "scatter_plot(x       = load_shots_list,\n",
    "             y       = fracs,\n",
    "             title   = \"Fraction of valid solutions\",\n",
    "             xlabel  = \"Shots\",\n",
    "             ylabel  = \"F_opt\",\n",
    "             save_as = \"valid_sol_12\",\n",
    "             ylim    = (0, 1.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Percentage of solutions containing the optimal solution and \n",
    "having less than 8 eigenstates:\"\"\")\n",
    "print()\n",
    "fracs = []\n",
    "for shot in load_shots_list:\n",
    "    frac = F_opt_finder(scan, shot, W, ['00100', '11011'], 8)\n",
    "    print(\"Case {0} shots: {1}%\".format(shot,frac*100))\n",
    "    fracs.append(frac)\n",
    "    \n",
    "scatter_plot(x       = load_shots_list,\n",
    "             y       = fracs,\n",
    "             title   = \"Fraction of valid solutions\",\n",
    "             xlabel  = \"Shots\",\n",
    "             ylabel  = \"F_opt\",\n",
    "             save_as = \"valid_sol_8\",\n",
    "             ylim    = (0, 1.2))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Solution Selection\n",
    "\n",
    "In the previous section we argued that a solution with too many eigenstates cannot be considered as a good solution, since finding the optimal eigenstate is basically the same as solving the problem using a *brute force* approach.\n",
    "\n",
    "It would be good to have a single criterion that allows us to select:\n",
    "- a solution that includes the optimal solution\n",
    "- a solution that, among all, has the lowest number of eigenstates.\n",
    "\n",
    "The first try should be given to the value of the solution cost funcion, since intuitively a low cost function corresponds to a large presence of the optimal eigenstate.\n",
    "\n",
    "Another figure of merit, recently proposed by IBM researcher, is the conditional value at risk (CVaR), a quantity borrowed from risk studies in finance. It consists in considering, instead of the cost function associated to the whole solution, the cost function associated to the $\\alpha N_{shots}$ lowest eigenvalues. Here $\\alpha \\in (0,1]$ and $N_{shots}$ is the number of shots used to evaluate the optimized ciruit.\n",
    "\n",
    "The idea of the CVaR is that it works better than the simple cost function in detecting the presence of eigenstates associated to low eigenvalues. For example, let consider two solutions:\n",
    "- S1 = 50% optimal solution + 50% eigenstate associated to highest eigenvalue;\n",
    "- S2 = 100% eigenstate associated to second-lowest eigenvalue.\n",
    "\n",
    "The cost function will be higher for S1 than for S2, since it considers the average of the lowest and highest eigenvalues for S1, while only the second-lowest eigenvalue for S2.\n",
    "On the other hand, if we select a value of $\\alpha$ between 0 and 0.5, CVaR will consider only the (up to) 50% lowest eigenvalues, so that CVaR prefers S1 to S2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost function value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average solution cost function vs shots\n",
    "scatter_plot(x       = df_plot.shots,\n",
    "             y       = df_plot.cost_func,\n",
    "             title   = \"Average solution cost function vs shots\",\n",
    "             xlabel  = \"Shots\",\n",
    "             ylabel  = \"Average solution cost function\",\n",
    "             save_as = \"cost_vs_shots_avg10\",\n",
    "             ylim    = (-8, -5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average solution cost function vs number of eigenstates in solution\n",
    "scatter_plot(x       = df_plot.eigenstates,\n",
    "             y       = df_plot.cost_func,\n",
    "             title   = \"Average cost function vs eigenstates number\",\n",
    "             xlabel  = \"Number of eigenstates\",\n",
    "             ylabel  = \"Average solution cost function\",\n",
    "             save_as = \"cost_vs_eigenst_avg10\",\n",
    "             ylim    = (-8, -5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each number of shots, get the solution giving\n",
    "# the lowest value of the cost function\n",
    "df_cost = df.groupby(['shots'])['cost_func']\n",
    "df_cost_plot = df.copy()\n",
    "\n",
    "# Group by shots and get the average number of eigenstates\n",
    "df_eig = df.groupby(['shots'])['eigenstates']\n",
    "#df_eig_plot = df.copy()\n",
    "\n",
    "df_cost_plot = df_cost_plot.assign(cost_min = df_cost.transform(min),\n",
    "                                   eig_mean = df_eig.transform(np.mean),\n",
    "                                   eig_min  = df_eig.transform(np.min))\n",
    "\n",
    "df_cost_plot = df_cost_plot[df_cost_plot['cost_func'] == df_cost_plot['cost_min']]\n",
    "\n",
    "df_cost_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of eigenstates in the solution:\n",
    "# - mean value (blue)\n",
    "# - when minimum cost function is selected (green)\n",
    "# - minimum value (orange)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "y1 = df_cost_plot.eig_mean\n",
    "y2 = df_cost_plot.eigenstates\n",
    "y3 = df_cost_plot.eig_min\n",
    "\n",
    "avg_plot = ax.scatter(x     = df_cost_plot.shots,\n",
    "                      y     = y1,\n",
    "                      label = \"average eigenstate number\")\n",
    "\n",
    "min_eig  = ax.scatter(x     = df_cost_plot.shots,\n",
    "                      y     = y3,\n",
    "                      label = \"minimum amount of eigenstates\")\n",
    "\n",
    "min_plot = ax.scatter(x = df_cost_plot.shots,\n",
    "                      y = y2,\n",
    "                      label = \"eigenstate number for min\\n cost function value\")\n",
    "\n",
    "ax.set_title(\"Eigenstates in solutions vs shots\")\n",
    "ax.set_xlabel(\"Shots\")\n",
    "ax.set_ylabel(\"Eigenstates in solution\")\n",
    "ax.legend(loc = \"upper right\")\n",
    "\n",
    "plot_name = \"eig_in_sol\"\n",
    "plt.savefig(plot_name + '.png')\n",
    "plt.savefig(plot_name + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional Value at Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVaR definition\n",
    "\n",
    "def cv_a_r(results, weights, alpha):\n",
    "    \"\"\" The function computes the conditional value at risk of a solution.                                                                                                                                  \n",
    "                                                                                                                                                                                                            \n",
    "    Inputs:                                                                                                                                                                                                 \n",
    "    results: the eigenstates-abundances dictionary returned by the optimization,                                                                                                                            \n",
    "    weights: the original QUBO matrix,                                                                                                                                                                      \n",
    "    alpha: the parameter of CVaR. Alpha c (0,1] and represents the fraction of                                                                                                                              \n",
    "    eigenstates considered in the computation.                                                                                                                                                              \n",
    "                                                                                                                                                                                                            \n",
    "    The computation of CVaR considers first the eigenstates associated to the lowest                                                                                                                        \n",
    "    eigenvalues and moves to eigenstates associated to increasing eigenvalues.                                                                                                                              \n",
    "    \"\"\"\n",
    "    # the eigenstates obtained by the evaluation of the circuit\n",
    "    eigenstates = list(results.keys())\n",
    "    \n",
    "    # create ndarray of eigenvalues\n",
    "    eigenvalues = np.array([])\n",
    "    for k in range(len(eigenstates)):\n",
    "        # ndarray of the digits extracted from the eigenstate string \n",
    "        x = np.array([int(num) for num in eigenstates[k]])\n",
    "        eigenvalues = np.append(eigenvalues, -x.dot(weights.dot(1-x)))\n",
    "    \n",
    "    # number of shots \n",
    "    shots = sum(results.values())\n",
    "\n",
    "    # Create a dataframe to manage all the variables used\n",
    "    # Start from the 'results' dictionary\n",
    "    cv_df = pd.DataFrame.from_dict(results, orient = 'index')\n",
    "    cv_df.reset_index(level=0, inplace=True)\n",
    "    cv_df.columns = [\"eigenstate\", \"abundance\"]\n",
    "    cv_df[\"abundance\"] = cv_df.abundance / shots\n",
    "    \n",
    "    # Adding eigenvalues\n",
    "    cv_df['eigenvalue'] = eigenvalues\n",
    "    \n",
    "    # Sort by eigenvalues (smaller first)\n",
    "    cv_df.sort_values(by = [\"eigenvalue\"], inplace = True)\n",
    "    \n",
    "    # Define 'cumulative eigenstate abundace': we want to sum\n",
    "    # term until cumul_abund is less or equal to alpha\n",
    "    cv_df[\"cumul_abund\"] = np.cumsum(cv_df[\"abundance\"])\n",
    "\n",
    "    # We are overstimating the abundace of the last term of CVaR\n",
    "    # by this quantity    \n",
    "    diff = cv_df[cv_df[\"cumul_abund\"] > 0.5].iloc[0].cumul_abund - alpha\n",
    "    # corrected value\n",
    "    new_abundance = cv_df[cv_df[\"cumul_abund\"] > 0.5].iloc[0].abundance - diff\n",
    "    \n",
    "    # location of the value to be corrected\n",
    "    qq = cv_df[cv_df[\"cumul_abund\"] > 0.5].iloc[0]    \n",
    "    # corrected abundance value\n",
    "    cv_df.at[qq.name, \"abundance\"]   = new_abundance\n",
    "    cv_df.at[qq.name, \"cumul_abund\"] = 0.5\n",
    "\n",
    "    # Actual CVaR computation\n",
    "    cv_df[\"cv\"] = (cv_df[\"abundance\"] * cv_df[\"eigenvalue\"]) / alpha   \n",
    "    cv_df[\"cumul_cv\"] = np.cumsum(cv_df[\"cv\"])\n",
    "\n",
    "    # CVaR value\n",
    "    cvar = cv_df.at[qq.name, \"cumul_cv\"]\n",
    "    \n",
    "    return cvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ncvar\"] = ncvar\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each number of shots, get the solution giving\n",
    "# the lowest value of the CVaR\n",
    "df_cvar = df.groupby(['shots'])['ncvar']\n",
    "df_cvar_plot = df.copy()\n",
    "\n",
    "# Group by shots and get the average number of eigenstates\n",
    "df_eig = df.groupby(['shots'])['eigenstates']\n",
    "#df_eig_plot = df.copy()\n",
    "\n",
    "df_cvar_plot = df_cvar_plot.assign(cvar_min = df_cvar.transform(min),\n",
    "                                   eig_mean = df_eig.transform(np.mean),\n",
    "                                   eig_min  = df_eig.transform(np.min))\n",
    "\n",
    "df_cvar_plot = df_cvar_plot[df_cvar_plot['ncvar'] == df_cvar_plot['cvar_min']]\n",
    "\n",
    "df_cvar_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of eigenstates in the solution:\n",
    "# - mean value (blue)\n",
    "# - when minimum cost function is selected (green)\n",
    "# - minimum value (orange)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "y1 = df_cvar_plot.eig_mean\n",
    "y2 = df_cvar_plot.eigenstates\n",
    "y3 = df_cvar_plot.eig_min\n",
    "\n",
    "avg_plot = ax.scatter(x     = df_cvar_plot.shots,\n",
    "                      y     = y1,\n",
    "                      label = \"average eigenstate number\")\n",
    "\n",
    "min_eig  = ax.scatter(x     = df_cvar_plot.shots,\n",
    "                      y     = y3,\n",
    "                      label = \"minimum amount of eigenstates\")\n",
    "\n",
    "min_plot = ax.scatter(x = df_cvar_plot.shots,\n",
    "                      y = y2,\n",
    "                      label = \"eigenstate number for min CVaR\")\n",
    "\n",
    "ax.set_title(\"Eigenstates in solutions vs shots\")\n",
    "ax.set_xlabel(\"Shots\")\n",
    "ax.set_ylabel(\"Eigenstates in solution\")\n",
    "ax.legend(loc = \"upper right\")\n",
    "\n",
    "plot_name = \"eig_in_sol_cvar\"\n",
    "plt.savefig(plot_name + '.png')\n",
    "plt.savefig(plot_name + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A more complex problem? (Work in progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Solution Selection\n",
    "\n",
    "The results of the previous study suggest that for the simple problem we are considering, all the optimizations in which at every iteration the circuit is measured at least 64 times, provide a solution containing the optimal solution. \n",
    "\n",
    "In general, we may expect that for more complex problems, just a fraction of the optimizations fulfills this goal.\n",
    "In that case, we would like to find a way to select a solution that with large probability contains the optimal solution.\n",
    "\n",
    "For this, we can try building a more complex problem, so that solving it is not as trivial as in the previous case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools to handle general graphs\n",
    "import networkx as nx\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Graph parameters \n",
    "n2 = 10\n",
    "V2 = np.arange(0, n, 1)\n",
    "E2 = [(0, 1, 2.0),\n",
    "      (0, 2, 1.0),\n",
    "      (3, 2, 3.0),\n",
    "      (0, 4, 3.0),\n",
    "      (4, 2, 1.0),\n",
    "      (7, 6, 1.0),\n",
    "      (6, 5, 1.0),\n",
    "      (5, 4, 6.0),\n",
    "      (5, 1, 1.0),\n",
    "      (0, 3, 1.0),\n",
    "      (6, 2, 1.0),\n",
    "      (4, 1, 5.0),\n",
    "      (5, 7, 2.0),\n",
    "      (3, 8, 1.0),\n",
    "      (2, 8, 1.0),\n",
    "      (6, 9, 1.0),\n",
    "      (7, 9, 1.0),\n",
    "      (8, 9, 1.0),\n",
    "      (4, 6, 1.0)] \n",
    "\n",
    "# Generating the graph with 10 nodes\n",
    "G2 = nx.Graph()\n",
    "G2.add_nodes_from(V2)\n",
    "G2.add_weighted_edges_from(E2)\n",
    "\n",
    "# Plot the graph\n",
    "colors       = ['r' for node in G2.nodes()]\n",
    "default_axes = plt.axes(frameon=True)\n",
    "pos          = nx.spring_layout(G2)\n",
    "\n",
    "nx.draw_networkx(G2, \n",
    "                 node_color = colors, \n",
    "                 node_size  = 600, \n",
    "                 alpha      = 1, \n",
    "                 ax         = default_axes, \n",
    "                 pos        = pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "# number of characters\n",
    "n2 = 10\n",
    "\n",
    "# W matrix definition\n",
    "W2 = np.zeros((n2,n2))\n",
    "\n",
    "for i in range(len(E2)):\n",
    "    W2[E2[i][0]][E2[i][1]] = E2[i][2] \n",
    "    W2[E2[i][1]][E2[i][0]] = E2[i][2] \n",
    "\n",
    "best_cost_brute = 0\n",
    "\n",
    "# computing all possible combinations\n",
    "for b in range(2**n2):\n",
    "    # x stores all the 2^n possible combinations of 0 and 1\n",
    "    # for a vector of length n \n",
    "    x = [int(t) for t in reversed(list(bin(b)[2:].zfill(n2)))]\n",
    "\n",
    "    # initialize cost function value\n",
    "    cost = 0\n",
    "    # scan all possible costs and keep the highest one\n",
    "    # (now we want to maximize our score!)\n",
    "    for i in range(n2):\n",
    "        for j in range(n2):\n",
    "            cost = cost + W2[i,j]*x[i]*(1 - x[j])\n",
    "    if best_cost_brute < cost:\n",
    "        best_cost_brute = cost\n",
    "        xbest_brute = x \n",
    "    #print('case = ' + str(x)+ ' score = ' + str(cost))\n",
    "\n",
    "# Showing results    \n",
    "colors = ['r' if xbest_brute[i] == 0 else 'b' for i in range(n2)]\n",
    "nx.draw_networkx(G2, node_color=colors)\n",
    "print('\\nBest solution = ' + str(xbest_brute) + ' cost = ' + str(best_cost_brute)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test once\n",
    "\n",
    "# Variables declaration\n",
    "WEIGHTS2    = W2\n",
    "N_QBITS2    = 8\n",
    "DEPTH2      = 2\n",
    "SHOTS2      = 512\n",
    "BACKEND2    = 'qasm_simulator'\n",
    "FINAL_EVAL2 = 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A small scan, but we can get some results\n",
    "\n",
    "from sys import getsizeof\n",
    "\n",
    "N_repetitions = 10\n",
    "shots_list = [64] # [128, 256, 512, 1024, 2048, 3072, 4096]\n",
    "\n",
    "for shot in shots_list:\n",
    "    results_current = []\n",
    "    output = 0\n",
    "    file_name = \"Scan_8qbits_\" + str(shot) + \".pkl\"\n",
    "    for rep in range(N_repetitions): \n",
    "        output = time_vs_shots(shot,\n",
    "                               WEIGHTS,\n",
    "                               N_QBITS,\n",
    "                               DEPTH,\n",
    "                               BACKEND,\n",
    "                               FINAL_EVAL) \n",
    "        \n",
    "        print(\"Done with\", str(shot), \"shots, repetition\", rep)\n",
    "        results_current.append(output)\n",
    "\n",
    "    save_object(results_current, file_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A small scan, just for testing\n",
    "scan_results = []\n",
    "\n",
    "shots_list = [128]#, 256, 512, 1024, 2048, 3072, 4096]\n",
    "\n",
    "for shot in shots_list:\n",
    "    output = time_vs_shots(shot,\n",
    "                           WEIGHTS2,\n",
    "                           N_QBITS2,\n",
    "                           DEPTH2,\n",
    "                           BACKEND2,\n",
    "                           FINAL_EVAL2) \n",
    "\n",
    "    scan_results.append(output)\n",
    "    \n",
    "# Normalize results for plotting\n",
    "for res in scan_results:\n",
    "    for key, value in res[1].items():\n",
    "        res[1][key] = res[1][key] / res[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of solutions containing the optimal solution:\")\n",
    "print()\n",
    "frac = F_opt_finder(scan_results, 128, W2, ['10010110','01101001'])\n",
    "frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Resolution: Quantum Approximate Optimization Algorithm (QAOA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To import all the functions defined in the notebook\n",
    "from  Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = random_graph_producer(n_vert = 5, n_edge = 6, seed = 2000, verbosity = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_solution, brute_cost, eig = brute_force_solver(M, verbosity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([[0, 1, 1, 0, 0],\n",
    "               [1, 0, 1, 0, 0],\n",
    "               [1, 1, 0, 1, 1],\n",
    "               [0, 0, 1, 0, 1],\n",
    "               [0, 0, 1, 1, 0]])\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_solution, brute_cost, eig = brute_force_solver(M, verbosity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entanglement parameter\n",
    "gamma = 0\n",
    "\n",
    "# single-qbit parameter\n",
    "beta = 0\n",
    "\n",
    "# prepare the quantum and classical resisters\n",
    "n_vertices = len(M)\n",
    "\n",
    "QAOA = QuantumCircuit(n_vertices, n_vertices)\n",
    "\n",
    "# apply the layer of Hadamard gates to all qubits\n",
    "QAOA.h(range(n_vertices))\n",
    "QAOA.barrier()\n",
    "\n",
    "# apply the Ising type gates with angle gamma along the edges in E\n",
    "for i in range(n_vertices):\n",
    "    for j in range(i, n_vertices):\n",
    "        if M[i,j] != 0:\n",
    "            # print(i,j, M[i,j])\n",
    "            QAOA.cu1(-2*gamma*M[i,j], i, j)\n",
    "            # QAOA.cu1(-2*gamma, i, j)\n",
    "            QAOA.u1(gamma, i)\n",
    "            QAOA.u1(gamma, j)\n",
    "    \n",
    "# then apply the single qubit X - rotations with angle beta to all qubits\n",
    "QAOA.barrier()\n",
    "QAOA.rx(2*beta, range(n_vertices))\n",
    "\n",
    "# Finally measure the result in the computational basis\n",
    "QAOA.barrier()\n",
    "QAOA.measure(range(n_vertices),range(n_vertices))\n",
    "    \n",
    "# draw the circuit for comparison\n",
    "QAOA.draw(output='mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the circuit on a simulator\n",
    "job = execute(QAOA, \n",
    "              backend = Aer.get_backend('qasm_simulator'), \n",
    "              shots   = 1024)\n",
    "\n",
    "result = job.result()\n",
    "\n",
    "# Print the result\n",
    "print(result.get_counts(QAOA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the result\n",
    "from qiskit.visualization import plot_histogram\n",
    "\n",
    "plot_histogram(result.get_counts(QAOA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the circuit as a parametric function\n",
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, execute, Aer\n",
    "\n",
    "def QAOA_circuit(gamma_beta, QUBO, depth): \n",
    "    \n",
    "    # prepare the quantum and classical registers\n",
    "    n_vertices = len(QUBO)\n",
    "\n",
    "    if len(gamma_beta) != 2*depth:\n",
    "        raise ValueError(\"'gamma_beta' parameter length must be equal to twice 'depth' parameter\")\n",
    "\n",
    "    gamma = gamma_beta[0:depth]\n",
    "    beta  = gamma_beta[depth:2*depth]\n",
    "    \n",
    "    # Define the Quantum and Classical Registers\n",
    "    q = QuantumRegister(n_vertices)\n",
    "    c = ClassicalRegister(n_vertices)\n",
    "\n",
    "    # Build the circuit\n",
    "    circuit = QuantumCircuit(q, c)\n",
    "\n",
    "    # apply the layer of Hadamard gates to all qubits\n",
    "    circuit.h(range(n_vertices))\n",
    "    circuit.barrier()\n",
    "           \n",
    "    for k in range(depth):\n",
    "        # apply the Ising type gates with angle gamma along the edges in E\n",
    "        for i in range(n_vertices):\n",
    "            for j in range(i,n_vertices):\n",
    "                if QUBO[i,j] != 0:\n",
    "                    # print(i,j, M[i,j])\n",
    "                    circuit.cu1(-2*gamma[k]*QUBO[i,j], i, j)\n",
    "                    circuit.u1(gamma[k], i)\n",
    "                    circuit.u1(gamma[k], j)\n",
    "    \n",
    "        # then apply the single qubit X-rotations with angle beta to all qubits\n",
    "        circuit.barrier()\n",
    "        circuit.rx(2*beta[k], range(n_vertices))\n",
    "\n",
    "    # Finally measure the result in the computational basis\n",
    "    circuit.barrier()\n",
    "    circuit.measure(range(n_vertices),range(n_vertices))\n",
    "    \n",
    "    return circuit    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw an example circuit\n",
    "n_qbits = 5 \n",
    "depth   = 5\n",
    "\n",
    "gamma_beta = np.zeros(2*depth)\n",
    "\n",
    "test_fig = QAOA_circuit(gamma_beta, M, depth).draw(output = 'mpl')\n",
    "test_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scipy implementation of the COBYLA optimizer\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "WEIGHTS = M\n",
    "N_QBITS = 5 \n",
    "DEPTH   = 10\n",
    "SHOTS   = 64\n",
    "ALGORITHM = \"QAOA\"\n",
    "ALPHA   = 1\n",
    "BACKEND = 'qasm_simulator'\n",
    "COST    = 'cost'\n",
    "VERBOSITY = False\n",
    "\n",
    "# Initial rotation angles\n",
    "gamma_beta = np.zeros(2*DEPTH)\n",
    "\n",
    "# Classical optimizer tuning\n",
    "res = minimize(fun     = cost_function_cobyla, \n",
    "               x0      = gamma_beta,        # the 'params' argument of 'cost_function_cobyla'\n",
    "               method  = 'COBYLA',          # we want to use the COBYLA optimization algorithm\n",
    "               options = {'maxiter': 500},  # maximum number of iterations\n",
    "               tol     = 0.0001,            # tolerance or final accuracy in the optimization \n",
    "               args    = (WEIGHTS, \n",
    "                          N_QBITS, \n",
    "                          DEPTH, \n",
    "                          SHOTS,\n",
    "                          COST,\n",
    "                          ALGORITHM,\n",
    "                          ALPHA,\n",
    "                          BACKEND,\n",
    "                          VERBOSITY))         # the arguments of 'cost_function_cobyla', except 'params'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the output distribution using the final parameters\n",
    "optimal_circuit = QAOA_circuit(res.x, \n",
    "                               M, \n",
    "                               DEPTH)\n",
    "\n",
    "backend = Aer.get_backend(BACKEND)\n",
    "\n",
    "counts = execute(optimal_circuit, \n",
    "                 backend, \n",
    "                 shots = 256).result().get_counts(optimal_circuit)\n",
    "\n",
    "print(\"Optimal rotation angles:\\n\", res.x)\n",
    "print()\n",
    "\n",
    "# To trust the optimizer is fine, but it is better to check ;) \n",
    "print(\"Cost function with the optimal angles (according to scipy):\", res.fun)\n",
    "print(\"Cost function with the optimal angles (actual evaluation):\",  cost_function_cobyla(res.x, \n",
    "                                                                                          WEIGHTS, \n",
    "                                                                                          N_QBITS, \n",
    "                                                                                          DEPTH, \n",
    "                                                                                          SHOTS,\n",
    "                                                                                          COST,\n",
    "                                                                                          ALGORITHM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the result\n",
    "from qiskit.visualization import plot_histogram\n",
    "\n",
    "plot_histogram(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 * counts['01010'] / 256 + 100 * counts['10101'] / 256"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
